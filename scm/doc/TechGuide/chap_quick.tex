\chapter{Quick Start Guide}
\label{chapter: quick}

This chapter provides instructions for obtaining and compiling  the GMTB SCM. The SCM code calls CCPP-compliant physics schemes through the CCPP framework code. As such, it requires the CCPP framework code and physics code, both of which are included as subdirectories within the SCM code. This package can be considered a simple example for an atmospheric model to interact with physics through the CCPP.

\section{Obtaining Code}

The source code bundle for the CCPP and SCM is provided through github.com.  This release repository contains the tested and supported version for general use.

\begin{enumerate}
    \item Download a compressed file or clone the source using
\begin{lstlisting}[language=bash]
git clone https://[username]@github.com/NCAR/gmtb-scm-release gmtb-scm
\end{lstlisting}
    and enter your github password when prompted.
    \item Check out the desired release number using
\begin{lstlisting}[language=bash]
git checkout [v2.0]
\end{lstlisting}
    \item Change directory into the project.
\begin{lstlisting}[language=bash]
cd gmtb-scm
\end{lstlisting}
\end{enumerate}

The CCPP framework can be found in the ccpp-framework subdirectory at this level.  The CCPP physics parameterizations can be found in the ccpp-physics subdirectory.

If you would like to contribute as a developer to this project, please see CCPP Developers Corner of the project website:

\url{https://dtcenter.org/gmtb/users/ccpp/developers/index.php}

There you will find links to all of the documentation pertinent to developers.

\section{System Requirements, Libraries, and Tools}
\label{section: systemrequirements}

The source code for the SCM and CCPP component is in the form of programs written in FORTRAN, FORTRAN 90, and C. In addition, the I/O relies on the netCDF libraries. Beyond the standard scripts, the build system relies on use of the Python scripting language, along with cmake, GNU make and date.

The basic requirements for building and running the CCPP and SCM bundle are listed below:
\begin{itemize}
    \item FORTRAN 90+ compiler (ifort v17+, gfortran v5.4+, pgf90 v17.9+)
    \item C compiler (icc v17+, gcc v5.4+, pgcc v17.9+)
    \item cmake v2.8.11+
    \item netCDF v4.x (not v3.x) with HDF5, ZLIB and SZIP
    \item Python v2.x (not v3.x)
    \item Libxml2 (tested with 2.2 and 2.9.1)
\end{itemize}

Because these tools and libraries are typically the purview of system administrators to install and maintain, they are considered  part of the basic system requirements.

There are several utility libraries provided in the SCM bundle, as external packages. These are built during the compilation phase, and include
\begin{itemize}
    \item bacio - Binary I/O Library
    \item sp - Spectral Transformation Library
    \item w3nco - GRIB decoder and encoder library
\end{itemize}

\subsection{Compilers}
The CCPP and SCM have been tested on a variety of
computing platforms. Currently the CCPP system is actively supported
on Linux and MacOS computing platforms using the Intel, PGI or GNU Fortran
compilers. Please use versions listed in the previous section as unforeseen
build issues may occur when using older compiler versions. Typically the best results come from using the
most recent version of a compiler. If you have problems with compilers, please check the ``Known Issues'' section of the
community website (\url{https://dtcenter.org/gmtb/users/ccpp/support/CCPP_KnownIssues.php}).

\section{Compiling SCM with CCPP}
\label{section: compiling}
The first step in compiling the CCPP and SCM is to match the physics variables (between what the host model -- SCM -- can provide and what is needed by physics schemes in the CCPP), and build the physics caps needed to use them.  Following this step, the top level build system will use \execout{cmake} to query system parameters and \execout{make} to compile the components.  A platform-specific script is provided to load modules and set the user environment for common platforms.  If you are not using one of these platforms, you will need to set up the same environment on your platform.
\begin{enumerate}
    \item Run the CCPP prebuild script to match required physics variables with those available from the dycore (SCM) and to generate physics caps and makefile segments.
\begin{lstlisting}[language=bash]
./ccpp-framework/scripts/ccpp_prebuild.py --model=SCM [--debug]
\end{lstlisting}
    \item Change directory to the top-level SCM directory.
\begin{lstlisting}[language=bash]
cd scm
\end{lstlisting}
    \item (Optional) Run the machine setup script if necessary. This script loads compiler modules (Fortran 2003-compliant), netCDF module, etc. and sets compiler environment variables. For \textit{t/csh} shells,
\begin{lstlisting}[language=csh]
source etc/Theia_setup_gnu.csh
source etc/Theia_setup_intel.csh
source etc/Theia_setup_pgi.csh
source etc/Cheyenne_setup_gnu.csh
source etc/Cheyenne_setup_intel.csh
source etc/Cheyenne_setup_pgi.csh
source etc/UBUNTU_setup.csh
source etc/CENTOS_setup.csh
source etc/MACOSX_setup.csh
\end{lstlisting}
For bourne/bash shells,
\begin{lstlisting}[language=bash]
. etc/Theia_setup_gnu.sh
. etc/Theia_setup_intel.sh
. etc/Theia_setup_pgi.sh
. etc/Cheyenne_setup_gnu.sh
. etc/Cheyenne_setup_intel.sh
. etc/Cheyenne_setup_pgi.sh
. etc/UBUNTU_setup.sh
. etc/CENTOS_setup.sh
. etc/MACOSX_setup.sh
\end{lstlisting}
\emph{Note:} If using a local Linux or Mac system, we provide instructions for how to set up your development system (compilers and libraries) in \execout{doc/README\_\{MACOSX,UBUNTU,CENTOS\}.txt}. If following these, you will need to run the respective setup script listed above. If your computing environment was previously set up to use modern compilers with an associated netCDF installation, it may not be necessary, although we recommend setting environment variables such as \execout{CC}, \execout{FC}, and \execout{NETCDF}.

    \item Make a build directory and change into it.
\begin{lstlisting}[language=bash]
mkdir bin && cd bin
\end{lstlisting}
    \item Invoke cmake on the source code to build.
\begin{lstlisting}[language=bash]
cmake ../src                          # without threading/OpenMP
cmake -DOPENMP=ON ../src               # with threading/OpenMP
cmake -DCMAKE_BUILD_TYPE=Debug ../src # debug mode
\end{lstlisting}
    \item If cmake cannot find \execout{libxml2} because it is installed in a non-standard location, add
\begin{lstlisting}[language=bash]
-DPC_LIBXML_INCLUDEDIR=... -DPC_LIBXML_LIBDIR=...
\end{lstlisting}
    to the cmake command.
    \item Compile. Add \execout{VERBOSE=1} to obtain more information on the build process.
\begin{lstlisting}[language=bash]
make
\end{lstlisting}
\end{enumerate}

The resulting executable may be found at \execout{./gmtb-scm} (Full path of \execout{gmtb-scm/scm/bin/gmtb-scm}). Depending on the system, it may be necessary to add the location of the CCPP framework and physics libraries to \execout{LD\_LIBRARY\_PATH} to run \execout{./gmtb-scm} (see next section).

If you encounter errors, please capture a log file from all of the steps, and contact the helpdesk at: \url{gmtb-help@ucar.edu}

\section{Run the SCM with a supplied case}
There are several test cases provided with this version of the SCM. For all cases, the SCM will go through the time steps, applying forcing and calling the physics defined in the suite definition file. A single command line argument is required to run the model, which is the name of the case configuration file (without the .nml extension) found in \execout{../etc/case\_config/}. For a quick test that the model works, choose to run the  \execout{twpice} case:
\begin{lstlisting}[language=bash]
./gmtb_scm twpice
\end{lstlisting}
If the run aborts with the error message
\begin{lstlisting}[language=bash]
gmtb_scm: libccppphys.so.1.0.0: cannot open shared object file: No such file or directory
\end{lstlisting}
the environment variable \execout{LD\_LIBRARY\_PATH} must be set to
\begin{lstlisting}[language=bash]
export LD_LIBRARY_PATH=$PWD/ccpp-physics:$LD_LIBRARY_PATH
\end{lstlisting}
before running the model.

A netCDF output file is generated in the location specified in the case
configuration file. Any standard netCDF file viewing or analysis tools may be used to
examine the output file (ncdump, ncview, NCL, etc).  For the supplied \execout{twpice.nml} case, it is located in:
\begin{lstlisting}[language=bash]
gmtb-scm/scm/bin/output_twpice/output.nc
\end{lstlisting}
or, simply,
\begin{lstlisting}[language=bash]
output_twpice/output.nc
\end{lstlisting}
if you still reside in the \execout{bin} directory from which you executed the model.

If using the model on HPC resources and significant amounts of processor time is anticipated for the experiments, it will likely be necessary to submit a job through the HPC's batch system. An example script has been included in the repository for running the model on Theia's batch system. It is located in \execout{gmtb-scm/scm/etc/gmtb\_scm\_run.py}. Edit the \execout{job\_name}, \execout{account}, etc. to suit your needs. The case name to be run is included in the \execout{command} variable. To use, invoke
\begin{lstlisting}[language=bash]
./gmtb_scm_run.py
\end{lstlisting}
from the \execout{gmtb-scm/scm/etc} directory.

Additional details regarding the SCM may be found in the remainder of this guide. More information on the CCPP can be found in the CCPP Developers' Corner available at \url{https://dtcenter.org/gmtb/users/ccpp/developers} and in the CCPP Developers' Guide at \url{https://dtcenter.org/gmtb/users/ccpp/docs}.
